from fastapi import FastAPI
from openai import OpenAI
from dotenv import load_dotenv
import os

from services.dogAnalyzer import analyze_dog_health
from models.chat import ChatRequest, ChatResponse  # âœ… ìƒˆë¡œ ì¶”ê°€

load_dotenv()

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

app = FastAPI()


def call_gpt(system_prompt: str, user_prompt: str) -> str:
    """ê³µí†µ GPT í˜¸ì¶œ í•¨ìˆ˜"""
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
        ],
    )
    return response.choices[0].message.content.strip()


@app.post("/chat", response_model=ChatResponse)
def chat(req: ChatRequest):
    """
    mode ì‚¬ìš© ê·œì¹™:
      - 2 : í”„ë¡œí•„ + ëŒ€í™” ê¸°ë°˜ ë°˜ë ¤ë™ë¬¼ ì¶”ì²œ (ì¶”ì²œ ëª¨ë“œ)
      - 3 : í”„ë¡œí•„ + ì§ì „ ì¶”ì²œ ê²°ê³¼ ê¸°ë°˜ ì´ë¯¸ì§€ ì„¤ëª…/í”„ë¡¬í”„íŠ¸ (ì´ë¯¸ì§€ ëª¨ë“œ)
      - None : ì¼ë°˜ ìƒë‹´ (í”„ë¡œí•„ ì°¸ê³ ë§Œ)
    ğŸ‘‰ 1ë²ˆ ëª¨ë“œëŠ” ìë°”ì—ì„œë§Œ ì²˜ë¦¬í•˜ê³ , ì´ APIëŠ” í˜¸ì¶œí•˜ì§€ ì•ŠëŠ”ë‹¤.
    """
    base_system = (
        "ë„ˆëŠ” ë°˜ë ¤ë™ë¬¼ ì…ì–‘ì„ ë„ì™€ì£¼ëŠ” ì¹œì ˆí•œ ìƒë‹´ ì±—ë´‡ì´ì•¼.\n"
        "ì‚¬ìš©ìì˜ ê±°ì£¼ í™˜ê²½, ì†Œë“ ìˆ˜ì¤€, ê°€ìš© ì‹œê°„, ê°€ì¡± êµ¬ì„± ë“±ì„ ê³ ë ¤í•´ì„œ "
        "í˜„ì‹¤ì ìœ¼ë¡œ ê°€ëŠ¥í•œ ë°˜ë ¤ë™ë¬¼ì„ ì¶”ì²œí•˜ê³  ì„¤ëª…í•´ì¤˜."
    )

    profile_info = req.profile_info or ""
    history = req.conversation_history or ""   # âœ… ìë°”ì—ì„œ ì˜¨ ëŒ€í™” íˆìŠ¤í† ë¦¬

    # ----- mode 2: í”„ë¡œí•„ + ëŒ€í™” ê¸°ë°˜ ë°˜ë ¤ë™ë¬¼ ì¶”ì²œ -----
    if req.mode == 2:
        system = (
            base_system
            + "\nì§€ê¸ˆì€ 'ë°˜ë ¤ë™ë¬¼ ì¶”ì²œ ëª¨ë“œ'ì•¼. "
            "ì‚¬ìš©ìì˜ í”„ë¡œí•„ê³¼ ì§€ê¸ˆê¹Œì§€ì˜ ëŒ€í™” ë‚´ìš©ì„ ìµœëŒ€í•œ í™œìš©í•´ì„œ "
            "ë¬´ì¡°ê±´ í•œ ì¢…ë¥˜ì˜ ë°˜ë ¤ë™ë¬¼ì„ ì¶”ì²œí•˜ê³ , ì´ ë™ë¬¼ì˜ ì´ë¦„ë§Œ ì¶œë ¥í•´ì•¼í•´.\n"
            "ì•„ë˜ ëª©ë¡ì€ JPetStoreì— ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ” ëª¨ë“  ë™ë¬¼ ì´ë¦„ ëª©ë¡ì´ì•¼. "
            "ë°˜ë ¤ë™ë¬¼ ì¶”ì²œ ì‹œ ë°˜ë“œì‹œ ì´ ëª©ë¡ ì•ˆì—ì„œë§Œ ì„ íƒí•´ì•¼ í•œë‹¤.\n\n"
            "[ì‚¬ìš© ê°€ëŠ¥í•œ ë™ë¬¼ ëª©ë¡]\n"
            "- Adult Male Amazon Parrot\n"
            "- Adult Male Finch\n"
            "- Adult Female Persian\n"
            "- Adult Male Persian\n"
            "- Tailless Manx\n"
            "- With tail Manx\n"
            "- Male Adult Bulldog\n"
            "- Female Puppy Bulldog\n"
            "- Adult Male Chihuahua\n"
            "- Adult Female Chihuahua\n"
            "- Spotted Adult Female Dalmation\n"
            "- Spotless Male Puppy Dalmation\n"
            "- Male Puppy Poodle\n"
            "- Adult Female Golden Retriever\n"
            "- Adult Male Labrador Retriever\n"
            "- Adult Female Labrador Retriever\n"
            "- Spotted Koi\n"
            "- Spotless Koi\n"
            "- Adult Male Goldfish\n"
            "- Adult Female Goldfish\n"
            "- Large Angelfish\n"
            "- Small Angelfish\n"
            "- Toothless Tiger Shark\n"
            "- Green Adult Iguana\n"
            "- Venomless Rattlesnake\n"
            "- Rattleless Rattlesnake\n\n"
            "ìœ„ ëª©ë¡ì— ì—†ëŠ” ë™ë¬¼ì€ ì ˆëŒ€ë¡œ ì¶”ì²œí•˜ì§€ ë§ˆ.\n"
            "ì¶œë ¥ í˜•ì‹ì€ ë°˜ë“œì‹œ 'ë™ë¬¼ ì´ë¦„' í•œ ì¤„ë§Œ ì¶œë ¥í•´ì•¼ í•œë‹¤."
        )


        # ë²„íŠ¼ë§Œ ëˆŒëŸ¬ë„ ë˜ê²Œ, messageê°€ ë¹„ì–´ ìˆìœ¼ë©´ ê¸°ë³¸ ë¬¸ì¥ìœ¼ë¡œ
        user_message = (req.message or "").strip() or \
            "ì§€ê¸ˆê¹Œì§€ì˜ í”„ë¡œí•„ê³¼ ëŒ€í™”ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì €ì—ê²Œ ë§ëŠ” ë°˜ë ¤ë™ë¬¼ì„ ì¶”ì²œí•´ ì£¼ì„¸ìš”."

        user_prompt = (
            f"[ì‚¬ìš©ì í”„ë¡œí•„]\n{profile_info}\n\n"
            f"[ì§€ê¸ˆê¹Œì§€ì˜ ëŒ€í™” ë‚´ìš©]\n{history}\n\n"
            f"[ì‚¬ìš©ìì˜ ìš”ì²­]\n{user_message}\n\n"
            "ìœ„ ëª¨ë“  ì •ë³´ë¥¼ ì¢…í•©í•´ì„œ ë°˜ë ¤ë™ë¬¼ì„ ì¶”ì²œí•´ì¤˜."
        )

        answer = call_gpt(system, user_prompt)


        return ChatResponse(
            answer=answer,
            ai_question=None,
            profile_info=None,
            image_url=None,
        )

    # ----- mode 3: í”„ë¡œí•„ + ì¶”ì²œ ê²°ê³¼ ê¸°ë°˜ ì´ë¯¸ì§€ ì„¤ëª… ëª¨ë“œ -----
    elif req.mode == 3:
        system = (
            base_system
            + "ì¶”ì²œëœ ë°˜ë ¤ë™ë¬¼ê³¼ ì‚¬ìš©ìê°€ í•¨ê»˜ ìˆëŠ” ì¥ë©´ì„ í•œ ì¥ì˜ ì‚¬ì§„ìœ¼ë¡œ ê·¸ë¦°ë‹¤ê³  ìƒê°í•˜ê³ , "
            "ì´ ì„¤ëª…ì€ ì´ë¯¸ì§€ ìƒì„± ëª¨ë¸ì— ë„£ì„ í”„ë¡¬í”„íŠ¸ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆì–´ì•¼ í•´."
        )

        user_prompt = (
            f"[ì‚¬ìš©ì í”„ë¡œí•„]\n{profile_info}\n\n"
            f"[ì¶”ì²œ ë°›ì€ ë™ë¬¼]\n{req.recommended_text}\n\n"
            "ì´ë¯¸ì§€ í•œ ì¥ì„ ê·¸ë¦°ë‹¤ê³  ìƒê°í•˜ê³ , êµ¬ì²´ì ì¸ ì¥ë©´ì„ ìì„¸íˆ ì„¤ëª…í•´ì¤˜."
        )

        prompt_for_image = call_gpt(system, user_prompt)

        # 3) ì‹¤ì œ ì´ë¯¸ì§€ ìƒì„± (URLë§Œ ë°›ê¸°)
        try:
            img_result = client.images.generate(
                model="gpt-image-1",
                prompt=prompt_for_image,
                size="1024x1024",
            )
            image_url = img_result.data[0].url

            answer_text = (
                "ì¶”ì²œí•´ ë“œë¦° ë°˜ë ¤ë™ë¬¼ê³¼ í•¨ê»˜ ìˆëŠ” ì¥ë©´ì„ ì´ë¯¸ì§€ë¡œ ìƒì„±í–ˆì–´ìš”.\n"
                "ì•„ë˜ URLì˜ ì´ë¯¸ì§€ë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”."
            )

            return ChatResponse(
                answer=answer_text,
                ai_question=None,
                profile_info=None,
                image_url=image_url,
            )

        except Exception as e:
            # â— ë“¤ì—¬ì“°ê¸° ìˆ˜ì •ë¨
            print("âŒ ì´ë¯¸ì§€ ìƒì„± ì¤‘ ì—ëŸ¬:", repr(e))

            return ChatResponse(
                answer=f"ì´ë¯¸ì§€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}",
                ai_question=None,
                profile_info=None,
                image_url=None,
            )


    # ----- ê¸°ë³¸ ëª¨ë“œ(None): ì¼ë°˜ ìƒë‹´ -----
    else:
        system = (
            base_system
            + "ë„ˆëŠ” ë°˜ë ¤ë™ë¬¼ ì…ì–‘ì„ ë„ì™€ì£¼ëŠ” ì¹œì ˆí•œ ìƒë‹´ ì±—ë´‡ì´ì•¼.\n"
    "ì‚¬ìš©ìê°€ ì œê³µí•œ í”„ë¡œí•„ ì •ë³´ëŠ” ì—¬ëŸ¬ ì¤„ì¼ ìˆ˜ ìˆì§€ë§Œ,"
    "í•­ìƒ ê°€ì¥ ë§ˆì§€ë§‰ ì§ˆë¬¸/ë‹µë³€ ë¸”ë¡ì´ ìµœì‹  ì •ë³´ë‹¤.\n"
    "ë°˜ë“œì‹œ ë§ˆì§€ë§‰ ë¸”ë¡ì˜ ê°’ë§Œ ì‚¬ìš©í•˜ê³ , ì´ì „ ë‚´ìš©ì€ ë¬´ì‹œí•´ì•¼ í•œë‹¤.\n"

        )

        if profile_info:
            user_prompt = (
                f"[ì‚¬ìš©ì í”„ë¡œí•„]\n{profile_info}\n\n"
                f"[ì‚¬ìš©ì ë°œí™”]\n{req.message}"
            )
        else:
            user_prompt = req.message

        answer = call_gpt(system, user_prompt)

        return ChatResponse(
            answer=answer,
            ai_question=None,
            profile_info=None,
            image_url=None,
        )


@app.post("/analyze_dog_health")
def analyze_health(req: ChatRequest):
    dog_health = analyze_dog_health(req.message)
    return {"dog_health": dog_health.model_dump()}
